우리는 LIME이라는 새로운 설명 기술을 제안합니다. 이 기술은 예측을 이해할 수 있고 신뢰할 수 있는 방식으로, 예측 주변에서 해석 가능한 모델을 학습함으로써 어떤 분류기의 예측도 설명합니다. 또한, 대표적인 개별 예측과 그 설명을 중복되지 않는 방식으로 제시함으로써 모델을 설명하는 방법을 제안합니다. 이 작업은 부분적 최적화 문제로 구성됩니다. 우리는 텍스트(예: 랜덤 포레스트)와 이미지 분류(예: 신경망)에 대한 다양한 모델을 설명함으로써 이 방법들의 유연성을 보여줍니다. 우리는 신뢰가 필요한 다양한 시나리오에서 설명의 유용성을 새로운 실험을 통해 보여줍니다. 이 실험에는 모의 실험과 인간 대상 실험이 포함되며, 예측을 신뢰해야 하는지 결정하기, 모델 선택하기, 신뢰할 수 없는 분류기 개선하기, 분류기를 신뢰할 수 없는 이유 식별하기 등이 있습니다.
  
